# Robots.txt for Kisheka Construction Accountability System
# Controls search engine crawling and indexing

# Default rules for all bots
User-agent: *

# Allow crawling of public pages
Allow: /
Allow: /auth/login
Allow: /auth/register

# Disallow private/protected areas
Disallow: /api/
Disallow: /dashboard
Disallow: /projects
Disallow: /material-requests
Disallow: /purchase-orders
Disallow: /expenses
Disallow: /labour
Disallow: /suppliers
Disallow: /analytics
Disallow: /reports
Disallow: /profile
Disallow: /investors
Disallow: /equipment
Disallow: /.next/

# Disallow specific crawl patterns
Disallow: /*?*sort=
Disallow: /*?*filter=
Disallow: /auth/

# Sitemap location
Sitemap: https://doshaki.netlify.app/sitemap.xml

# Crawl delay for responsible crawling
Crawl-delay: 1
Request-rate: 1/1s

# Google-specific optimizations
User-agent: Googlebot
Allow: /

# Bing-specific optimizations
User-agent: Bingbot
Allow: /
